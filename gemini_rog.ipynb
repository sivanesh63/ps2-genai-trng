{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1abb21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model=genai.GenerativeModel('gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a278f720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knowledge-base/employees\\\\Alex Chen.md',\n",
       " 'knowledge-base/employees\\\\Alex Harper.md',\n",
       " 'knowledge-base/employees\\\\Alex Thomson.md',\n",
       " 'knowledge-base/employees\\\\Avery Lancaster.md',\n",
       " 'knowledge-base/employees\\\\Emily Carter.md',\n",
       " 'knowledge-base/employees\\\\Emily Tran.md',\n",
       " 'knowledge-base/employees\\\\Jordan Blake.md',\n",
       " 'knowledge-base/employees\\\\Jordan K. Bishop.md',\n",
       " 'knowledge-base/employees\\\\Maxine Thompson.md',\n",
       " 'knowledge-base/employees\\\\Oliver Spencer.md',\n",
       " 'knowledge-base/employees\\\\Samantha Greene.md',\n",
       " 'knowledge-base/employees\\\\Samuel Trenton.md']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"knowledge-base/employees/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7005929",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "\n",
    "employees = glob.glob(\"knowledge-base/employees/*\")\n",
    "\n",
    "for employee in employees:\n",
    "    name = employee.split(' ')[-1][:-3]\n",
    "    doc = \"\"\n",
    "    with open(employee, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc = f.read()\n",
    "    context[name]=doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05646216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# HR Record\\n\\n# Alex Chen\\n\\n## Summary\\n- **Date of Birth:** March 15, 1990  \\n- **Job Title:** Backend Software Engineer  \\n- **Location:** San Francisco, California  \\n\\n## Insurellm Career Progression\\n- **April 2020:** Joined Insurellm as a Junior Backend Developer. Focused on building APIs to enhance customer data security.\\n- **October 2021:** Promoted to Backend Software Engineer. Took on leadership for a key project developing a microservices architecture to support the company\\'s growing platform.\\n- **March 2023:** Awarded the title of Senior Backend Software Engineer due to exemplary performance in scaling backend services, reducing downtime by 30% over six months.\\n\\n## Annual Performance History\\n- **2020:**  \\n  - Completed onboarding successfully.  \\n  - Met expectations in delivering project milestones.  \\n  - Received positive feedback from the team leads.\\n\\n- **2021:**  \\n  - Achieved a 95% success rate in project delivery timelines.  \\n  - Awarded \"Rising Star\" at the annual company gala for outstanding contributions.  \\n\\n- **2022:**  \\n  - Exceeded goals by optimizing existing backend code, improving system performance by 25%.  \\n  - Conducted training sessions for junior developers, fostering knowledge sharing.  \\n\\n- **2023:**  \\n  - Led a major overhaul of the API internal architecture, enhancing security protocols.  \\n  - Contributed to the company’s transition to a cloud-based infrastructure.  \\n  - Received an overall performance rating of 4.8/5.\\n\\n## Compensation History\\n- **2020:** Base Salary: $80,000  \\n- **2021:** Base Salary Increase to $90,000; Received a performance bonus of $5,000.  \\n- **2022:** Base Salary Increase to $100,000; Performance bonus of $7,500 due to exceptional project outcomes.  \\n- **2023:** Base Salary Increase to $115,000; Performance bonus of $10,000 for leading pivotal projects.\\n\\n## Other HR Notes\\n- Participates regularly in Insurellm\\'s Diversity & Inclusion initiatives, championing tech accessibility for underrepresented communities.\\n- Completed several certifications in cloud architecture and DevOps, contributing to professional growth.\\n- Plans for a professional development course in AI and machine learning to further enhance backend capabilities in Insurellm\\'s offerings.\\n- Acknowledged for volunteer efforts in local tech meetups, bringing seasoned engineers to mentor aspiring coders.  \\n\\nAlex Chen continues to be a vital asset at Insurellm, contributing significantly to innovative backend solutions that help shape the future of insurance technology.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['Chen']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "475d0f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985  \\n- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \\n- **Location**: San Francisco, California  \\n\\n## Insurellm Career Progression\\n- **2015 - Present**: Co-Founder & CEO  \\n  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \\n\\n- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.  \\n\\n- **2010 - 2013**: Business Analyst at Edge Analytics  \\n  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\\n\\n## Annual Performance History\\n- **2015**: **Exceeds Expectations**  \\n  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \\n\\n- **2016**: **Meets Expectations**  \\n  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \\n\\n- **2017**: **Developing**  \\n  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \\n\\n- **2018**: **Exceeds Expectations**  \\n  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \\n\\n- **2019**: **Meets Expectations**  \\n  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \\n\\n- **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \\n\\n- **2021**: **Exceptional**  \\n  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \\n\\n- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \\n\\n- **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\\n\\n## Compensation History\\n- **2015**: $150,000 base salary + Significant equity stake  \\n- **2016**: $160,000 base salary + Equity increase  \\n- **2017**: $150,000 base salary + Decrease in bonus due to performance  \\n- **2018**: $180,000 base salary + performance bonus of $30,000  \\n- **2019**: $185,000 base salary + market adjustment + $5,000 bonus  \\n- **2020**: $170,000 base salary (temporary reduction due to COVID-19)  \\n- **2021**: $200,000 base salary + performance bonus of $50,000  \\n- **2022**: $210,000 base salary + retention bonus  \\n- **2023**: $225,000 base salary + $75,000 performance bonus  \\n\\n## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \\n- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \\n- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\\n- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \\n\\nAvery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[\"Lancaster\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9634968",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = glob.glob(\"knowledge-base/products/*\")\n",
    "\n",
    "for product in products:\n",
    "    name = product.split(os.sep)[-1][:-3]\n",
    "    doc = \"\"\n",
    "    with open(product, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc = f.read()\n",
    "    context[name]=doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fc7f057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Chen', 'Harper', 'Thomson', 'Lancaster', 'Carter', 'Tran', 'Blake', 'Bishop', 'Thompson', 'Spencer', 'Greene', 'Trenton', 'Carllm', 'Homellm', 'Markellm', 'Rellm'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eca18906",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an expert in answering accurate questions about Insurellm, the Insurance Tech company. Give brief, accurate answers. If you don't know the answer, say so. Do not make anything up if you haven't been provided with relevant context.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1be3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    relevant_context = []\n",
    "    for context_title, context_details in context.items():\n",
    "        if context_title.lower() in message.lower():\n",
    "            relevant_context.append(context_details)\n",
    "    return relevant_context   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c648f0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"# Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985  \\n- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \\n- **Location**: San Francisco, California  \\n\\n## Insurellm Career Progression\\n- **2015 - Present**: Co-Founder & CEO  \\n  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \\n\\n- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.  \\n\\n- **2010 - 2013**: Business Analyst at Edge Analytics  \\n  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\\n\\n## Annual Performance History\\n- **2015**: **Exceeds Expectations**  \\n  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \\n\\n- **2016**: **Meets Expectations**  \\n  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \\n\\n- **2017**: **Developing**  \\n  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \\n\\n- **2018**: **Exceeds Expectations**  \\n  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \\n\\n- **2019**: **Meets Expectations**  \\n  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \\n\\n- **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \\n\\n- **2021**: **Exceptional**  \\n  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \\n\\n- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \\n\\n- **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\\n\\n## Compensation History\\n- **2015**: $150,000 base salary + Significant equity stake  \\n- **2016**: $160,000 base salary + Equity increase  \\n- **2017**: $150,000 base salary + Decrease in bonus due to performance  \\n- **2018**: $180,000 base salary + performance bonus of $30,000  \\n- **2019**: $185,000 base salary + market adjustment + $5,000 bonus  \\n- **2020**: $170,000 base salary (temporary reduction due to COVID-19)  \\n- **2021**: $200,000 base salary + performance bonus of $50,000  \\n- **2022**: $210,000 base salary + retention bonus  \\n- **2023**: $225,000 base salary + $75,000 performance bonus  \\n\\n## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \\n- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \\n- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\\n- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \\n\\nAvery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_context(\"Who is lancaster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c37fe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Product Summary\\n\\n# Carllm\\n\\n## Summary\\n\\nCarllm is an innovative auto insurance product developed by Insurellm, designed to streamline the way insurance companies offer coverage to their customers. Powered by cutting-edge artificial intelligence, Carllm utilizes advanced algorithms to deliver personalized auto insurance solutions, ensuring optimal coverage while minimizing costs. With a robust infrastructure that supports both B2B and B2C customers, Carllm redefines the auto insurance landscape and empowers insurance providers to enhance customer satisfaction and retention.\\n\\n## Features\\n\\n- **AI-Powered Risk Assessment**: Carllm leverages artificial intelligence to analyze driver behavior, vehicle conditions, and historical claims data. This enables insurers to make informed decisions and set competitive premiums that reflect true risk profiles.\\n\\n- **Instant Quoting**: With Carllm, insurance companies can offer near-instant quotes to customers, enhancing the customer experience. The AI engine processes data in real-time, drastically reducing the time it takes to generate quotes.\\n\\n- **Customizable Coverage Plans**: Carllm allows insurers to create flexible and tailored insurance packages based on individual customer needs. This customization improves customer engagement and retention.\\n\\n- **Fraud Detection**: The product incorporates advanced analytics to identify potentially fraudulent claims, significantly reducing the risk of losses for insurance providers.\\n\\n- **Customer Insights Dashboard**: Carllm provides insurers with a powerful dashboard that offers deep insights into customer behavior, claims patterns, and market trends, enabling informed decision-making and strategic planning.\\n\\n- **Mobile Integration**: Carllm is designed to work seamlessly with mobile applications, providing both insurers and end-users access to policy management and claims reporting on the go.\\n\\n- **Automated Customer Support**: Leveraging AI chatbots, Carllm offers 24/7 customer support, helping to resolve inquiries quickly and efficiently, thus improving customer satisfaction.\\n\\n## Pricing\\n\\nCarllm is offered under a subscription-based pricing model tailored to meet the needs of insurance companies of all sizes. Our pricing tiers are designed to provide maximum flexibility and value:\\n\\n- **Basic Tier**: $1,000/month\\n  - Ideal for small insurance firms.\\n  - Access to core features and standard reporting.\\n\\n- **Professional Tier**: $2,500/month\\n  - For medium-sized companies.\\n  - All Basic Tier features plus advanced analytics and fraud detection.\\n\\n- **Enterprise Tier**: $5,000/month\\n  - Customized solutions for large insurance firms.\\n  - Comprehensive support, full feature access, and integration with existing systems.\\n\\nContact our sales team for a personalized quote and discover how Carllm can transform your auto insurance offerings!\\n\\n## 2025-2026 Roadmap\\n\\nIn our commitment to continuous improvement and innovation, Insurellm has outlined the following roadmap for Carllm:\\n\\n### Q1 2025: Launch Feature Enhancements\\n- **Expanded data integrations** for better risk assessment.\\n- **Enhanced fraud detection algorithms** to reduce losses.\\n\\n### Q2 2025: Customer Experience Improvements\\n- Launch of a new **mobile app** for end-users.\\n- Introduction of **telematics-based pricing** to provide even more tailored coverage options.\\n\\n### Q3 2025: Global Expansion\\n- Begin pilot programs for international insurance markets.\\n- Collaborate with local insurers to offer compliant, localized versions of Carllm.\\n\\n### Q4 2025: AI and Machine Learning Upgrades\\n- Implement next-gen machine learning models for predictive analysis.\\n- Roll out customer insights dashboard updates based on user feedback.\\n\\n### 2026: Scaling and Partnerships\\n- Increase partnerships with automakers for integrated insurance solutions.\\n- Enhance the **AI customer support system** to include multi-language support.\\n\\nCarllm is not just an auto insurance product; it is a transformative tool for the insurance industry. Join us on this exciting journey as we redefine the future of auto insurance with technology and customer-centric solutions.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_context(\"Who is Avery and what is carllm?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e09cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        model = \"models/embedding-001\"\n",
    "        title = \"embedding-doc\"\n",
    "\n",
    "        embeddings = []\n",
    "        for doc in input:\n",
    "            response = genai.embed_content(\n",
    "                model=model,\n",
    "                content=doc,\n",
    "                task_type=\"retrieval_document\",\n",
    "                title=title\n",
    "            )\n",
    "            embeddings.append(response[\"embedding\"])\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d7fd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "def create_chroma_db(documents, name):\n",
    "    chroma_client = chromadb.Client()\n",
    "    db = chroma_client.create_collection(\n",
    "        name=name,\n",
    "        embedding_function=GeminiEmbeddingFunction()\n",
    "    )\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        db.add(documents=[doc], ids=[str(i)])\n",
    "    \n",
    "    return db\n",
    "\n",
    "md_files = glob.glob(\"knowledge-base/employees/*.md\")\n",
    "\n",
    "# Read the content from each markdown file\n",
    "documents = []\n",
    "for file_path in md_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        documents.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed9e922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIVANESHWARAN\\AppData\\Local\\Temp\\ipykernel_3224\\256308290.py:9: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function=GeminiEmbeddingFunction()\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Collection [employee-knowledge-db] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m chroma_client = chromadb.Client()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create collection with Gemini embedding function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m db = \u001b[43mchroma_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43memployee-knowledge-db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGeminiEmbeddingFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Add documents to ChromaDB collection\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SIVANESHWARAN\\anaconda3\\envs\\llms\\Lib\\site-packages\\chromadb\\api\\client.py:168\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m configuration_ef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    166\u001b[39m     configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    177\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    178\u001b[39m     model=model,\n\u001b[32m    179\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    180\u001b[39m     data_loader=data_loader,\n\u001b[32m    181\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SIVANESHWARAN\\anaconda3\\envs\\llms\\Lib\\site-packages\\chromadb\\api\\rust.py:227\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     configuration_json_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration_json_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m collection_model = CollectionModel(\n\u001b[32m    231\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    232\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     database=collection.database,\n\u001b[32m    238\u001b[39m )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInternalError\u001b[39m: Collection [employee-knowledge-db] already exists"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Create ChromaDB client\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Create collection with Gemini embedding function\n",
    "db = chroma_client.create_collection(\n",
    "    name=\"employee-knowledge-db\",\n",
    "    embedding_function=GeminiEmbeddingFunction()\n",
    ")\n",
    "\n",
    "# Add documents to ChromaDB collection\n",
    "for i, doc in enumerate(documents):\n",
    "    db.add(\n",
    "        documents=[doc],\n",
    "        ids=[f\"doc_{i}\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543cefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# HR Record\\n\\n# Emily Tran\\n\\n## Summary\\n- **Date of Birth:** March 18, 1991  \\n- **Job Title:** Digital Marketing Specialist  \\n- **Location:** San Francisco, CA  \\n\\n---\\n\\n## Insurellm Career Progression\\n- **February 2020 - Present**: Digital Marketing Specialist  \\n   - Emily Tran has been pivotal in enhancing Insurellm\\'s online presence through targeted social media campaigns and SEO strategies.\\n   - Successfully managed a team of interns for the \\'Spring Into Safety\\' initiative, increasing customer engagement by 35%.\\n\\n- **June 2018 - January 2020**: Marketing Coordinator  \\n  - Assisted in the development and execution of marketing campaigns to promote Insurellm\\'s products.\\n  - Collected and analyzed data on customer demographics to inform Insurellm’s marketing strategies.\\n\\n- **January 2017 - May 2018**: Marketing Intern  \\n  - Supported the Marketing team by collaborating on content creation and digital advertising projects.\\n  - Gained hands-on experience with marketing automation tools, enriching her skillset for her role in Insurellm.\\n\\n---\\n\\n## Annual Performance History\\n- **2023**:  \\n  - Performance Rating: Exceeds Expectations  \\n  - Key Achievements: Led the \"Tech the Halls\" campaign that resulted in a 50% increase in leads during the holiday season. \\n  - Emily Tran\\'s innovative strategies and attention to detail have made her stand out among her peers.\\n\\n- **2022**:  \\n  - Performance Rating: Meets Expectations  \\n  - Key Achievements: Enhanced Insurellm\\'s email marketing strategy, achieving a 25% open rate increase.\\n\\n- **2021**:  \\n  - Performance Rating: Meets Expectations  \\n  - Key Achievements: Contributed to the launch of a customer referral program that resulted in a 15% growth in B2C customers.\\n\\n---\\n\\n## Compensation History\\n- **2023**:  \\n  - Base Salary: $75,000  \\n  - Bonus: $10,000 for exceeding annual targets.\\n\\n- **2022**:  \\n  - Base Salary: $70,000  \\n  - Bonus: $5,000 for achieving marketing milestones.\\n\\n- **2021**:  \\n  - Base Salary: $67,500  \\n  - No bonus due to reallocation of marketing funds during the pandemic.\\n\\n---\\n\\n## Other HR Notes\\n- **Training Completed**:  \\n  - Advanced Digital Marketing Workshop (2021)  \\n  - Analytics and Reporting in Digital Advertising (2022)\\n\\n- **Professional Development Goals**:  \\n  - Emily Tran aims to become a Marketing Manager within the next two years, focusing on leading larger campaigns and developing junior team members.\\n\\n- **Hobbies**:  \\n  - Emily enjoys photography and regularly contributes to Insurellm\\'s social media content with her own high-quality images.\\n  - She is also passionate about sustainability and organizes monthly team volunteer events for environmental awareness. \\n\\n---\\n\\nEmily Tran continues to be a valuable asset to Insurellm, driving innovative marketing strategies that resonate with a diverse customer base. Her contributions have significantly enhanced the company\\'s branding and customer outreach efforts.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_relevant_passage(query, db):\n",
    "    passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
    "    return passage\n",
    "\n",
    "\n",
    "passage = get_relevant_passage(query, db)\n",
    "passage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "    passage = relevant_passage.replace('\"', '').replace(\"'\", \"\").replace(\"\\n\", \" \")\n",
    "    return f\"\"\"\n",
    "You are a helpful assistant. Use the passage to answer clearly.\n",
    "QUESTION: {query}\n",
    "PASSAGE: {passage}\n",
    "ANSWER:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c537696",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do you use the touchscreen in the Google car?\"\n",
    "prompt = make_prompt(query, passage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef7021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIVANESHWARAN\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    try:\n",
    "        context = get_relevant_passage(message)\n",
    "        prompt = make_prompt(message, context)\n",
    "        response = model.generate_content(prompt)\n",
    "        return f\"**Prompt Used:**\\n{prompt}\\n\\n**Gemini Answer:**\\n{response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\" **Error:** {e}\"\n",
    "\n",
    "# 4. Launch chatbot\n",
    "gr.ChatInterface(fn=chat, title=\"Gemini RAG Chatbot\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
