{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced48ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, enables computers to mimic human-like intelligence by learning from data, rather than being explicitly programmed for every scenario.\n",
      "\n",
      "At its core, AI works by using **algorithms** – sets of rules or instructions – to analyze vast amounts of data. Think of showing an AI thousands of cat images; it doesn't just know what a cat is, it learns to identify common patterns – ears, whiskers, eyes – that define a cat. This learning process builds a \"model,\" which is essentially a sophisticated pattern recognition system.\n",
      "\n",
      "A common approach is **Machine Learning**, where the AI system is \"trained\" on data. During this training, the algorithms adjust their internal parameters based on feedback, minimizing errors and improving accuracy. For instance, if it incorrectly identifies a dog as a cat, it learns from that mistake.\n",
      "\n",
      "Many AI systems use **neural networks**, inspired by the human brain's structure. These networks consist of interconnected \"nodes\" or \"neurons\" that process information in layers, allowing for the recognition of complex patterns.\n",
      "\n",
      "Once trained, when presented with new, unseen data, the model applies its learned patterns to make predictions or decisions. This enables AI to perform tasks like facial recognition, voice understanding, language translation, and even autonomous driving. The more quality data and computational power it receives, the more capable and accurate the AI becomes at simulating aspects of human cognition.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Explain how AI works in 300 words\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af226ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='AI, or Artificial Intelligence, enables computers to mimic human-like intelligence by learning from data, rather than being explicitly programmed for every scenario.\\n\\nAt its core, AI works by using **algorithms** – sets of rules or instructions – to analyze vast amounts of data. Think of showing an AI thousands of cat images; it doesn\\'t just know what a cat is, it learns to identify common patterns – ears, whiskers, eyes – that define a cat. This learning process builds a \"model,\" which is essentially a sophisticated pattern recognition system.\\n\\nA common approach is **Machine Learning**, where the AI system is \"trained\" on data. During this training, the algorithms adjust their internal parameters based on feedback, minimizing errors and improving accuracy. For instance, if it incorrectly identifies a dog as a cat, it learns from that mistake.\\n\\nMany AI systems use **neural networks**, inspired by the human brain\\'s structure. These networks consist of interconnected \"nodes\" or \"neurons\" that process information in layers, allowing for the recognition of complex patterns.\\n\\nOnce trained, when presented with new, unseen data, the model applies its learned patterns to make predictions or decisions. This enables AI to perform tasks like facial recognition, voice understanding, language translation, and even autonomous driving. The more quality data and computational power it receives, the more capable and accurate the AI becomes at simulating aspects of human cognition.')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.5-flash', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=283, candidates_tokens_details=None, prompt_token_count=12, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=12)], thoughts_token_count=1384, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=1679, traffic_type=None), automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18003d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 1679\n",
      "Prompt Tokens: 12\n",
      "Generated Tokens: 283\n"
     ]
    }
   ],
   "source": [
    "total_tokens = response.usage_metadata.total_token_count\n",
    "prompt_tokens = response.usage_metadata.prompt_token_count\n",
    "candidates_tokens = response.usage_metadata.candidates_token_count\n",
    "\n",
    "print(f\"Total Tokens: {total_tokens}\")\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Generated Tokens: {candidates_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115ef5a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f237d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe43bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3232a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the time series model? \n",
      "\n",
      "Because it was too committed to the past!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai\n",
    "\n",
    "\n",
    "system_message = \"You are a helpful assisstant\"\n",
    "user_prompt = \"Explain cloud computing\"\n",
    "\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c31e5f-3d96-471c-a053-86be3543c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assisstant\"\n",
    "user_prompt = \"Explain cloud computing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fd367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Why did the data scientist break up with the time series model? \\n\\nBecause it was too committed to the past!\\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"avg_logprobs\": -0.32713912963867187\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 22,\n",
       "        \"candidates_token_count\": 25,\n",
       "        \"total_token_count\": 47,\n",
       "        \"prompt_tokens_details\": [\n",
       "          {\n",
       "            \"modality\": \"TEXT\",\n",
       "            \"token_count\": 22\n",
       "          }\n",
       "        ],\n",
       "        \"candidates_tokens_details\": [\n",
       "          {\n",
       "            \"modality\": \"TEXT\",\n",
       "            \"token_count\": 25\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"model_version\": \"gemini-2.0-flash\"\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ed289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
