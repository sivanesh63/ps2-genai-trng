{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f8b3d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6147e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down vector embeddings and vector databases.\n",
      "\n",
      "**1. Vector Embeddings: Turning Data into Meaningful Numbers**\n",
      "\n",
      "Imagine you want a computer to understand the *meaning* of words, sentences, images, or even user profiles.  Computers are good at working with numbers, not abstract concepts.  That's where vector embeddings come in.\n",
      "\n",
      "* **What they are:** Vector embeddings are a way to represent data (text, images, audio, etc.) as a *vector* of numbers in a high-dimensional space.  Think of it like plotting points in a multi-dimensional graph, where each dimension represents a different aspect or feature of the data.\n",
      "\n",
      "* **How they work (the core idea):**\n",
      "\n",
      "    * **Capture Semantic Relationships:** The key idea is that items that are *similar* in meaning or content will be located *close* to each other in this high-dimensional space.  Items that are *different* will be further apart.  This \"closeness\" is measured by distance metrics like cosine similarity, Euclidean distance, or dot product.\n",
      "\n",
      "    * **Training the Model:**  Creating good vector embeddings requires training a model on a large dataset.  The model learns to adjust the vector representations so that similar items are closer together.  Common techniques for training include:\n",
      "\n",
      "        * **Word Embeddings (for text):**  Models like Word2Vec, GloVe, and FastText learn to embed words based on the context in which they appear in text.  For example, \"king\" and \"queen\" would be closer together than \"king\" and \"dog\".  More advanced models use Transformers like BERT, RoBERTa, and others to generate contextualized word embeddings (the embedding of a word depends on the surrounding words in the sentence).\n",
      "        * **Image Embeddings:** Convolutional Neural Networks (CNNs) are often used to extract features from images and then project them into an embedding space. Similar images will have similar embeddings.\n",
      "        * **Audio Embeddings:**  Techniques like spectrogram analysis and neural networks can be used to generate embeddings for audio data, capturing characteristics like timbre, pitch, and rhythm.\n",
      "\n",
      "* **Example (Simplified):**\n",
      "\n",
      "   Let's say you have the following words:\n",
      "\n",
      "   * \"dog\"\n",
      "   * \"cat\"\n",
      "   * \"apple\"\n",
      "   * \"banana\"\n",
      "\n",
      "   A vector embedding model might produce the following (very simplified) 2-dimensional vectors:\n",
      "\n",
      "   * dog: [0.8, 0.2]\n",
      "   * cat: [0.7, 0.3]\n",
      "   * apple: [0.1, 0.9]\n",
      "   * banana: [0.2, 0.8]\n",
      "\n",
      "   Notice that \"dog\" and \"cat\" are closer together (they have similar vector values) than \"dog\" and \"apple.\"  This represents that \"dog\" and \"cat\" are semantically more similar.\n",
      "\n",
      "**2. Vector Databases: Storing and Searching Embeddings Efficiently**\n",
      "\n",
      "Now that you have all these vector embeddings, you need a way to store them and, more importantly, *search* them efficiently.  That's where vector databases come in.\n",
      "\n",
      "* **What they are:** Vector databases are specialized databases designed to store, manage, and search vector embeddings at scale. They are optimized for similarity search (finding the nearest neighbors of a given vector).\n",
      "\n",
      "* **Why they're needed (the limitations of traditional databases):**\n",
      "\n",
      "    * **Inefficient Similarity Search:**  Traditional databases (like relational databases or NoSQL databases) are not well-suited for performing similarity searches on high-dimensional vectors.\n",
      "        * Searching for nearest neighbors in a standard database would typically involve comparing the query vector to *every* vector in the database (a full table scan).  This becomes extremely slow as the number of vectors grows, especially with high dimensionality (e.g., vectors with hundreds or thousands of dimensions).\n",
      "    * **Lack of Vector-Specific Indexing:**  Traditional databases don't have indexing mechanisms optimized for vector similarity.  They rely on indexes designed for exact matches or range queries, which are not effective for finding approximate nearest neighbors.\n",
      "\n",
      "* **How Vector Databases Work (Key Concepts):**\n",
      "\n",
      "    * **Approximate Nearest Neighbor (ANN) Search:**  Vector databases use ANN algorithms to provide fast (but potentially approximate) similarity searches.  ANN algorithms trade off some accuracy for significant speed improvements.  Common ANN techniques include:\n",
      "        * **Hierarchical Navigable Small World (HNSW):**  Creates a multi-layered graph where each layer is a progressively smaller subset of the data.  Search starts at the top layer and navigates down to the bottom layer to find the nearest neighbors.\n",
      "        * **Inverted File Index (IVF):**  Partitions the vector space into clusters.  The query vector is first assigned to a cluster, and then only the vectors within that cluster are searched.\n",
      "        * **Product Quantization (PQ):**  Compresses vectors by quantizing them into a smaller set of centroids. This reduces the memory footprint and speeds up distance calculations.\n",
      "    * **Indexing Techniques:**  Vector databases use specialized indexing techniques tailored for high-dimensional data to further accelerate similarity search.\n",
      "    * **Scalability:** Designed to handle massive datasets of vector embeddings and high query loads.  They often employ distributed architectures for horizontal scalability.\n",
      "    * **Metadata Support:**  Allow you to associate metadata (e.g., document ID, user ID, timestamps) with each vector embedding.  This metadata can be used to filter or refine search results.\n",
      "\n",
      "**3. Why We Need Vector Databases (Use Cases):**\n",
      "\n",
      "* **Semantic Search:** Search for documents or content based on meaning rather than keywords. This is a significant improvement over keyword-based search.  Imagine searching for \"dog breeds that are good with children\" and getting results about golden retrievers and labrador retrievers, even if those words aren't explicitly in your search query.\n",
      "* **Recommendation Systems:**  Recommend products, movies, or articles to users based on their past behavior or preferences.  Embed user profiles and content items as vectors and find the nearest neighbors to generate recommendations.\n",
      "* **Image Retrieval:** Search for similar images based on visual content.  Upload an image and find other images that are visually similar.\n",
      "* **Fraud Detection:** Identify fraudulent transactions or activities by embedding user behaviors and detecting anomalies.\n",
      "* **Anomaly Detection:** Finding unusual patterns in data by identifying data points that are far away from other data points in the embedding space.\n",
      "* **Question Answering:**  Embed questions and passages of text as vectors and find the passages that are most relevant to answering the question.\n",
      "* **Chatbots and Conversational AI:** Improve the accuracy and relevance of chatbot responses by embedding user queries and finding the most similar responses in a knowledge base.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "* **Vector embeddings** transform data into numerical representations that capture semantic meaning.\n",
      "* **Vector databases** are specialized databases optimized for storing, managing, and searching vector embeddings at scale, using techniques like ANN search for efficient similarity search.\n",
      "* Vector databases enable powerful applications like semantic search, recommendation systems, and image retrieval by allowing you to find items that are *similar in meaning* rather than just *similar in keywords*. They are essential for working with the output of modern machine learning models and unlocking the potential of unstructured data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "user_prompt = \"Explain me Vector Embeddings and what are vector databases, why do we need vector databases? \"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=user_prompt\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed0d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Okay, let\\'s break down vector embeddings and vector databases.\\n\\n**1. Vector Embeddings: Turning Data into Meaningful Numbers**\\n\\nImagine you want a computer to understand the *meaning* of words, sentences, images, or even user profiles.  Computers are good at working with numbers, not abstract concepts.  That\\'s where vector embeddings come in.\\n\\n* **What they are:** Vector embeddings are a way to represent data (text, images, audio, etc.) as a *vector* of numbers in a high-dimensional space.  Think of it like plotting points in a multi-dimensional graph, where each dimension represents a different aspect or feature of the data.\\n\\n* **How they work (the core idea):**\\n\\n    * **Capture Semantic Relationships:** The key idea is that items that are *similar* in meaning or content will be located *close* to each other in this high-dimensional space.  Items that are *different* will be further apart.  This \"closeness\" is measured by distance metrics like cosine similarity, Euclidean distance, or dot product.\\n\\n    * **Training the Model:**  Creating good vector embeddings requires training a model on a large dataset.  The model learns to adjust the vector representations so that similar items are closer together.  Common techniques for training include:\\n\\n        * **Word Embeddings (for text):**  Models like Word2Vec, GloVe, and FastText learn to embed words based on the context in which they appear in text.  For example, \"king\" and \"queen\" would be closer together than \"king\" and \"dog\".  More advanced models use Transformers like BERT, RoBERTa, and others to generate contextualized word embeddings (the embedding of a word depends on the surrounding words in the sentence).\\n        * **Image Embeddings:** Convolutional Neural Networks (CNNs) are often used to extract features from images and then project them into an embedding space. Similar images will have similar embeddings.\\n        * **Audio Embeddings:**  Techniques like spectrogram analysis and neural networks can be used to generate embeddings for audio data, capturing characteristics like timbre, pitch, and rhythm.\\n\\n* **Example (Simplified):**\\n\\n   Let\\'s say you have the following words:\\n\\n   * \"dog\"\\n   * \"cat\"\\n   * \"apple\"\\n   * \"banana\"\\n\\n   A vector embedding model might produce the following (very simplified) 2-dimensional vectors:\\n\\n   * dog: [0.8, 0.2]\\n   * cat: [0.7, 0.3]\\n   * apple: [0.1, 0.9]\\n   * banana: [0.2, 0.8]\\n\\n   Notice that \"dog\" and \"cat\" are closer together (they have similar vector values) than \"dog\" and \"apple.\"  This represents that \"dog\" and \"cat\" are semantically more similar.\\n\\n**2. Vector Databases: Storing and Searching Embeddings Efficiently**\\n\\nNow that you have all these vector embeddings, you need a way to store them and, more importantly, *search* them efficiently.  That\\'s where vector databases come in.\\n\\n* **What they are:** Vector databases are specialized databases designed to store, manage, and search vector embeddings at scale. They are optimized for similarity search (finding the nearest neighbors of a given vector).\\n\\n* **Why they\\'re needed (the limitations of traditional databases):**\\n\\n    * **Inefficient Similarity Search:**  Traditional databases (like relational databases or NoSQL databases) are not well-suited for performing similarity searches on high-dimensional vectors.\\n        * Searching for nearest neighbors in a standard database would typically involve comparing the query vector to *every* vector in the database (a full table scan).  This becomes extremely slow as the number of vectors grows, especially with high dimensionality (e.g., vectors with hundreds or thousands of dimensions).\\n    * **Lack of Vector-Specific Indexing:**  Traditional databases don\\'t have indexing mechanisms optimized for vector similarity.  They rely on indexes designed for exact matches or range queries, which are not effective for finding approximate nearest neighbors.\\n\\n* **How Vector Databases Work (Key Concepts):**\\n\\n    * **Approximate Nearest Neighbor (ANN) Search:**  Vector databases use ANN algorithms to provide fast (but potentially approximate) similarity searches.  ANN algorithms trade off some accuracy for significant speed improvements.  Common ANN techniques include:\\n        * **Hierarchical Navigable Small World (HNSW):**  Creates a multi-layered graph where each layer is a progressively smaller subset of the data.  Search starts at the top layer and navigates down to the bottom layer to find the nearest neighbors.\\n        * **Inverted File Index (IVF):**  Partitions the vector space into clusters.  The query vector is first assigned to a cluster, and then only the vectors within that cluster are searched.\\n        * **Product Quantization (PQ):**  Compresses vectors by quantizing them into a smaller set of centroids. This reduces the memory footprint and speeds up distance calculations.\\n    * **Indexing Techniques:**  Vector databases use specialized indexing techniques tailored for high-dimensional data to further accelerate similarity search.\\n    * **Scalability:** Designed to handle massive datasets of vector embeddings and high query loads.  They often employ distributed architectures for horizontal scalability.\\n    * **Metadata Support:**  Allow you to associate metadata (e.g., document ID, user ID, timestamps) with each vector embedding.  This metadata can be used to filter or refine search results.\\n\\n**3. Why We Need Vector Databases (Use Cases):**\\n\\n* **Semantic Search:** Search for documents or content based on meaning rather than keywords. This is a significant improvement over keyword-based search.  Imagine searching for \"dog breeds that are good with children\" and getting results about golden retrievers and labrador retrievers, even if those words aren\\'t explicitly in your search query.\\n* **Recommendation Systems:**  Recommend products, movies, or articles to users based on their past behavior or preferences.  Embed user profiles and content items as vectors and find the nearest neighbors to generate recommendations.\\n* **Image Retrieval:** Search for similar images based on visual content.  Upload an image and find other images that are visually similar.\\n* **Fraud Detection:** Identify fraudulent transactions or activities by embedding user behaviors and detecting anomalies.\\n* **Anomaly Detection:** Finding unusual patterns in data by identifying data points that are far away from other data points in the embedding space.\\n* **Question Answering:**  Embed questions and passages of text as vectors and find the passages that are most relevant to answering the question.\\n* **Chatbots and Conversational AI:** Improve the accuracy and relevance of chatbot responses by embedding user queries and finding the most similar responses in a knowledge base.\\n\\n**In summary:**\\n\\n* **Vector embeddings** transform data into numerical representations that capture semantic meaning.\\n* **Vector databases** are specialized databases optimized for storing, managing, and searching vector embeddings at scale, using techniques like ANN search for efficient similarity search.\\n* Vector databases enable powerful applications like semantic search, recommendation systems, and image retrieval by allowing you to find items that are *similar in meaning* rather than just *similar in keywords*. They are essential for working with the output of modern machine learning models and unlocking the potential of unstructured data.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=-0.34054918624024705, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=1538, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1538)], prompt_token_count=19, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=19)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=1557, traffic_type=None), automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf18a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 1557\n",
      "Prompt Tokens: 19\n",
      "Generated Tokens: 1538\n"
     ]
    }
   ],
   "source": [
    "total_tokens = response.usage_metadata.total_token_count\n",
    "prompt_tokens = response.usage_metadata.prompt_token_count\n",
    "candidates_tokens = response.usage_metadata.candidates_token_count\n",
    "\n",
    "print(f\"Total Tokens: {total_tokens}\")\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Generated Tokens: {candidates_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92846a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
